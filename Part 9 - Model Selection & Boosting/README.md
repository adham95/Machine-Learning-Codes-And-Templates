# Model Selection & Boosting

Welcome to Part 9 - Model Selection & Boosting!


After we built our Machine Learning models, some questions remained unanswered:

1. How to deal with the bias variance tradeoff when building a model and evaluating its performance ?

2. How to choose the optimal values for the hyperparameters (the parameters that are not learned) ?

3. How to find the most appropriate Machine Learning model for my business problem ?

In this part we will answer these questions thanks to Model Selection techniques including:

1. k-Fold Cross Validation

2. Grid Search

Eventually we see one of the most powerful Machine Learning model, that has become more and more popular: XGBoost.
